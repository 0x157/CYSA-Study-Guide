# Vulnerability Management Activities

## Vulnerability Identification

- vulnerability scanning = automation of security checks against org's systems; point out weaknesses in system
  - key aspect of network security
  - single purpose tools, do not analyze context, can't chain exploits (so a bunch of small vulnerabilities that can create a big hole only appear as small vulnerabilities), they don't act like an attacker- they act like an automated system searching for a predetermined list of potential vulnerabilities

### Regulatory Environments

- many organizations are forced to operate under the control of laws, rules, and regulations of governments, industry groups, or other regulatory bodies
- orgs within regulatory environments generally have to deal with compliance in some way, and that compliance often has a security aspect

#### ISO/IEC 27001 Standard

- The International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC) jointly maintain this standard on Information Security Management Systems (ISMS)
- VERY common voluntary standard
- three stages of certification:
  1. desk-side audit to ensure documentation for vulnerability management
  2. implementation audit to ensure documentation is followed
  3. surveilance audit ensures that implementation is continued

#### Payment Card Industry Data Security Standard (PCI DSS)

- applies to all orgs who process credit card payments from the five major issuers:
  - Visa
  - Mastercard
  - Amex
  - Discover
  - JCB
- requirement 11 focuses on regular testing of security systems and processes
  - requires internal and external scans every quarter and whenever significant changes are implemented
  - high risk vulernabilities must be resolved

#### Health Insurance Portability and Accountability Act (HIPAA)

- creates penalties for failure to protect protected health information (PHI)
- requires orgs to conduct vulnerability assessments and implement reasonable security measures

#### Corporate Security Policy

- high level statement of security policy within an org established by senior management
- accompanied by issue-specific and system-specific security policies that prescribe security implementations at a slightly more detailed level with smaller scope

### Data Classification

- classification tag specifies sensitivity of data to which it is attached
- outside of the government, data classification levels are specified at a company-level
  - additional governance exists for classified data for government and contractor data that are not included here
- common levels include the following:
  - private - could raise personal privacy concerns
  - confidential - data could seriously damage organization
  - proprietary (or sensitive) = data could cause some damage, not major
  - public - no adverse effect of release
- classification levels should not overlap
- classification levels should consider the following factors:
  - level of damage caused by disclosure
  - level of damage caused by loss of integrity
  - lost opportunities
  - regulatory requirements
  - data age
  - relevance of data to security posture

### Asset Inventory

- you can't protect what you don't know about
- inventory includes anything of value to an org
  - determining value tends to be more difficult than establishing inventory

#### Servers

- losing track of everything on a server leaves it vulnerable to attacks on obscure pre-installed apps (*cough cough* Windows Server *cough*)
- misconfigurations and ignoring unused features leaves servers vulnerable to exploits on those services
  - need everything you use and secure everything you use and remove the dross because it just provides more attack surface
- shadow IT = unmonitored activities by other members of an org to add functionality that security and sys admin teams are unaware of and thus don't secure

#### Endpoints

- devices used by end-users
- most common entry point into a network
- the decentralized, unmanaged distribution and use of these devices has historically made them a very weak point for many security operations

#### Critical Assets

- everything needed to perform essential functions of an org
- must be heavily defended because the org relies on them for revenue

#### Noncritical Assets

- not imperative for successful security operation
- lower priority than critical assets
- always consider the business implications of security decisions

### Active vs Passive Scanning 

- scanning = method to learn about a network/system/device through its responses
- scanner come in one of three flavors:
  1. network mappers
  2. host/port scanners
  3. web app vulnerability scanners
- (not from book:) active scanning = poke the devices and see what comes back
- (also not from book:) passive scanning = monitor what happens on a network or system without stimulating it directly

### Mapping/Enumeration

- network mapping aims to understand network layout (topology discovery): 
  - perimeter networks
  - demilitarized zones (DMZs)
  - key network devices
- steps for mapping: 
  - sweep the network - see what devices are online; commonly done with *NMap*
  - after a sweep an attacker may make a second pass to fill in details on interesting results

#### Port Scanning

- port scanners = programs for probing open ports on a host
- used for service discovery
- OS may be inferred based on OS fingerprinting done by some port scanners (not always reliably)

#### Web App Vulnerability Scanning

- web app vulnerability scanner = automated tool for scanning web apps for security vulnerabilities including SQLi, CSRF, command injection, and improper server configs, among others
- additional features for these scanners may be implemented with plug-ins and APIs
- these scanners have become commonly used by genuine attackers, not just red teamers

## Scanning Parameters and Criteria

- no single solution as to optimal scanning frequency - it's about the why
  - make the calculations up front about when is best for the business, how often is sufficient, and so on
  - setting up periodic rather than ad hoc scans also provides you with a better understanding of exactly what you security posture is

### Risks Associated with Scanning Activities

- risk appetite = amount of risk a business is willing to accept
  - find the balance between acceptable risk and acceptable resource expenditure to minimize those risks
  - risk can never be zero, so there must be some tradeoff

### Regulatory Requirements

- scanning frequency requirements may be handed to you by regulations
- semiannual scans are considered a **minimum** by industry experts
  - probably as a condition of "acceptable security"

### Technical Constraints

- security operations are constrained by a number of factors: personnel, time, compute, etc.
- technical constraints are those on personnel and computational resources like memory space or compute time
  - identifying constraints is a good first step
  - increasing scans is possible when constraints are greater than the current operation uses

### Workflow

- establishing consistent patterns of work within security teams helps to ensure that all of their tasks are completed with regularity and consistency
- when defenders know what to expect, then deviations from the norm become even more obvious

### Sensitivity Levels

- even when conducting security assessments, it's important that the process of scanning or any other operations do not violate individual security
  - example: scanning, finding, and saving an employee's plain text list of passwords on their work computer
- security should also not compromise assets in a way that lowers their value 
  - example: if a security scan (or other operation) hurts the availability of a server processing payments, then there needs to be a mechanism to pick up the slack from that server while it's being scanned

### Vulnerability Feed

- different feeds will eventually have all the same vulnerabilities, but they may pick them up sooner or later than one another
- pick a feed that closely matches with your scanning frequency
- since vulnerabilities will be reported between scans, security professionals need to determine whether an out-of-cycle scan is worth the trouble in order to justify the extra cost

### Scope

- managing the scope of a scan is important both from a cost perspective and for managing the availability of assets

### Noncredentialed vs Credentialed

- noncredentialed scans look at the environment from the perspective of an outsider/unauthorized user
  - black box
  - more realistic, more secure
  - less insight into the environment
- credentialed scan does the opposite, uses perspective of insider/permitted entity
  - white box
  - credentialed scans should not get full admin rights unless absolutely necessary to achieve full scope (should be a rarity if it happens ever)

### Server-Based vs Agent-Based

- agent-based scanners require process(es) running on the scanned device
  - take up compute from each device
- server-based scanners do not require processes to run on scanned devices
  - require more network bandwidth 

### Internal vs External

- external scanners look at devices from outside of the (local) network
  - see what most attackers will see
- internal scanners look from within the network
  - large corporations may have massive internal networks so the possibility of an infiltration is higher
  - internal scanners are usually surplus to all but the largest networks

### Types of Data

- when reporting on data discovered from scans, consider the following:
  - intended audience
  - regulatory requirements
  - prioritized assets

### Tool Updates and Plug-Ins

- since new vulnerabilities are discovered all the time, keeping scanners up to date with these vulnerabilities is what makes them effective
- plug-in = simple program that looks for the presence of a single flaw

### SCAP

- Security Content Automation Protocol (SCAP) = NIST-developed standard for vulnerability management
- scanners can be SCAP certified and have SCAP module appropriate to an environment
- enables automation

### Special Considerations

- scanners need their own set of permissions in order to run on a network (aside from credentialed/noncredentialed considerations)
  - some kind of service account is best for this
- make sure that your scan isn't being picked up by IDS/IPS on network
- scanners have their own set of vulnerabilities that can be attacked
  - these need to be patched and managed just like the rest of the system

## Intrusion Prevention System, Intrusion Detection System, and Firewall Settings

- vulnerability scanning and IDS/IPS/firewalls don't play well together
- whitelisting scanners and publishing planned scans can help limit friction between security teams/systems

### Generating Reports

- vulnerability scans need to end with an actionable report of vulnerabilities in the scanned system
- automate report formatting, statistics, distribution as admin

#### Automated vs Manual Distribution

- unless you are the only security person/admin, automate distribution of scan reports so that the right people get the right information as soon as possible

#### Validation

- once the report is in the hands of an analyst, it needs to be validated for accuracy
- once distributed to the first tier of security professionals and sysadmins, the validity of every reported vulnerability needs to be ensured before it goes any further 

#### True Positives

- when an accurate vulnerability report comes through, analysts need to determine the fastest, most effective way of solving the problem that aligns with business needs

#### Compare to Best Practices or Compliance

- the Defense Information Systems Agency (DISA) of the DoD creates Security Technical Implementation Guides (STIGs) which are combined with NSA guides for configuration standards for the DoD
- STIGs guide system hardening efforts
  - not all STIGs are open to the public- some require PKI certs

#### Reconcile Results

- take notes on everything: they will make your life so much easier
  - what you did
  - why you did it
  - why it worked/didn't work
- notes help investigations

#### Review Related Logs and/or Other Data Sources

- correlate scanning results with expected state of system/network
  - not just in terms of vulnerabilities, but everything; example: if a port isn't supposed to be open and is, even if it isn't a "vulnerability" it's still a problem
- review of logs will help determine whether vulnerabilities have already been exploited
- Security Information and Event Management (SIEM) tools help correlate all of this

#### Determine Trends

- somehow track how vulnerabilities have changed over time on your system/network (either through built-in scanning/SIEM functionality or your own tooling)
- ticketing software can also help track vulnerabilities over time

#### False Positives

- false positives cause small issues in small orgs with a few dozen/hundred endpoints, but they are multiplied in large orgs with thousands/tens of thousands of endpoints
- ensuring that tests check the right indicators can limit these errors
  - check the assumptions of the program
  - custom systems have higher rates of false positives because more assumptions of the scanner devs are wrong

#### True Negatives

- true negatives are awesome: no vulnerability is the best vulnerability
- impossible to prove: absence of evidence is not evidence of absence

#### False Negatives

- incorrect assertion of absence of a vulnerability
- type 2 error
- results in false sense of security
- possible causes include:
  - incorrect type of scan initiated
  - vulnerability is too new

### Remediation

- scanners try to provide as much detail about discovered vulnerabilities as possible
- remediation should be begun as soon as possible
- continuous, thoughtful, thorough, and iterative processes are needed for maximally effective remediation of vulnerabilities
- add notes on remediation efforts to scan results and reports

#### Patching

- patching is a necessary evil because of the tradeoff between downtime and security
- the predictability of patching cycles and the delay between patch release and installation convinced Microsoft to move away from its regular cycles and focus auto-updates instead
  - limiting the resultant downtime from system restarts might also be a good idea

#### Prioritizing

- given the number of vulnerabilities that may discovered from any scan, there needs to be some method for determining which will be dealt with first
- considerations should be given to technical capacity of security team and business goals among others

#### Criticality

- Nessus and OpenVAS provide basic severity scores to help sysadmins and sec analysts make determinations on what needs to be attended first

#### Hardening

- dynamic process to make it harder to break into networks/systems to begin with, and harder to stay hidden if successful
- balance usability and security
  - if you focus too much on security, you negate the business benefits of security because the asset becomes unusable
  - there needs to be parallel focus on both security and usability, it is possible to enhance both simultaneously with intelligent solutions
- if you don't need something, **TURN IT OFF**

##### Exam Tip

- well-known ports = TCP and UDP ports 0-1023
- registered ports = TCP and UDP ports 1024-49151
- ephemeral/dynamic ports = TCP and UDP ports 49152+

#### Compensating Controls

- controls that are used to help minimize security risks but don't quite meet security goals because of some constraint
- better than nothing, but not ideal

#### Risk Acceptance

- not every vulnerability can be remediated, in this case there is acceptance of the risk it brings
- when a vulnerability is accepted, it must still be catalogued and there must be some internal process to keep track of it so appropriate action can be taken if situations change

##### Verification of Mitigation

- implement some kind of testing process to ensure that security controls were implemented correctly

## Inhibitors to Remediation

- remediation is not always smooth sailing- obstacles arise often, some solutions are offered below

### Memorandum of Understanding (MOU)

- outlines duties/expectations of all relevant actors
- cover what happens when after who does what how so that everyone goes home happy

### Service Level Agreement (SLA)

- an agreement between an IT service provider and recipient which outlines roles, responsibilities, and limits of services provided

### Organizational Governance

- finding a means of balancing the divergining interests of various stakeholders within a single organization
- strong communication enables good decisions

### Business Process Interruption

- because of how streamlined many IT operations are, companies will do everything they can to avoid interruptions because they struggle to afford them

### Degrading Functionality

- there must be a balance between implementing security and maintaining the level of operation in IT services

### Legacy and Proprietary Systems

- age of these systems is often due to the complexity or size of the problem they solve
  - makes replacement tricky if feasible at all
- finding one's way through these systems is hard enough, finding their inevitable vulnerabilities is a massive challenge
  - easy and common to just leave it alone and hope that no attacker can figure it out either
- these systems may be too difficult to patch for the personnel available and the time disposable
  - add security to other levels
  - add compensating controls
  - monitor them

## Ongoing Scanning and Continuous Monitoring

- subscription scanning tools are a thing
  - offered from the cloud
- scanning frequently and remediating quickly is important no matter how you scan
